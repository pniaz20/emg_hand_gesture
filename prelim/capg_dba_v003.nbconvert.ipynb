{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition with CAPG DB-a Dataset (one subject for testing)\n",
    "\n",
    "In this preliminary effort, we will try to perform hand gesture recognition from CAPG DBA dataset.\n",
    "\n",
    "In this version:\n",
    "\n",
    "- EMG data is normalized with the recorded MVC data\n",
    "- EMG data (already preprocessed) **will not be processed** further.\n",
    "- There is **no feature engineering**; raw EMG data will be used.\n",
    "- **1D CNN** with simple architecture will be used.\n",
    "- **Training data:** 9 trials per subject per gesture\n",
    "- **Test data:** 1 trial per subject per gesture\n",
    "- K-fold cross-validation will be performed.\n",
    "\n",
    "**NOTE** This code has been tested with:\n",
    "```\n",
    "    numpy version:        1.23.5\n",
    "    scipy version:        1.9.3\n",
    "    sklearn version:      1.2.0\n",
    "    seaborn version:      0.12.1\n",
    "    pandas version:       1.5.2\n",
    "    torch version:        1.12.1+cu113\n",
    "    matplotlib version:   3.6.2\n",
    "    CUDA version:         11.2\n",
    "    cuDNN version:        8.1.0\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Preliminaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:37.098046Z",
     "iopub.status.busy": "2022-12-24T19:34:37.097104Z",
     "iopub.status.idle": "2022-12-24T19:34:44.241698Z",
     "shell.execute_reply": "2022-12-24T19:34:44.240024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory is:  /scratch/users/pniaz20/REPO/comp541-project/prelim\n",
      "Current Working Directory is now:  /scratch/users/pniaz20/REPO/comp541-project/prelim\n",
      "numpy version:        1.18.5\n",
      "scipy version:        1.4.1\n",
      "sklearn version:      1.0.2\n",
      "seaborn version:      0.11.2\n",
      "pandas version:       1.4.2\n",
      "torch version:        1.12.1+cu113\n",
      "matplotlib version:   3.5.1\n",
      "Checking to see if PyTorch recognizes GPU...\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "direc = os.getcwd()\n",
    "print(\"Current Working Directory is: \", direc)\n",
    "KUACC = False\n",
    "if \"scratch\" in direc: # We are using the cluster\n",
    "    KUACC = True\n",
    "    homedir = os.path.expanduser(\"~\")\n",
    "    os.chdir(os.path.join(homedir,\"REPO/comp541-project/prelim/\"))\n",
    "    direc = os.getcwd()\n",
    "    print(\"Current Working Directory is now: \", direc)\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../data/\")\n",
    "import torch\n",
    "from datasets_torch import *\n",
    "from models_torch import *\n",
    "from utils_torch import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import statistics\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# Print versions\n",
    "print(\"numpy version:       \", np.__version__)\n",
    "print(\"scipy version:       \", sp.__version__)\n",
    "print(\"sklearn version:     \", sklearn.__version__)\n",
    "print(\"seaborn version:     \", sns.__version__)\n",
    "print(\"pandas version:      \", pd.__version__)\n",
    "print(\"torch version:       \", torch.__version__)\n",
    "print(\"matplotlib version:  \", matplotlib.__version__)\n",
    "\n",
    "\n",
    "# Checking to see if CUDA is available for us\n",
    "print(\"Checking to see if PyTorch recognizes GPU...\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Whether to use latex rendering in plots throughout the notebook\n",
    "USE_TEX = False\n",
    "FONT_SIZE = 12\n",
    "\n",
    "# Setting matplotlib plotting variables\n",
    "if USE_TEX:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Computer Modern Roman\"]\n",
    "    })\n",
    "else:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\"]\n",
    "    })\n",
    "\n",
    "# Do not plot figures inline (only useful for cluster)\n",
    "# %matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Hyperparameters and Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:44.247368Z",
     "iopub.status.busy": "2022-12-24T19:34:44.246588Z",
     "iopub.status.idle": "2022-12-24T19:34:44.254314Z",
     "shell.execute_reply": "2022-12-24T19:34:44.253188Z"
    }
   },
   "outputs": [],
   "source": [
    "k_fold_study = {\n",
    "    'code':'capg_dba_v003',\n",
    "    'package':'torch',\n",
    "    'dataset':'capg',\n",
    "    'subdataset':'dba',\n",
    "    \"training_accuracies\": [],\n",
    "    \"validation_accuracies\": [],\n",
    "    \"testset_accuracies\": [],\n",
    "    \"history_training_loss\": [],\n",
    "    \"history_training_metrics\": [],\n",
    "    \"history_validation_loss\": [],\n",
    "    \"history_validation_metrics\": [],\n",
    "    \"preprocessing\":\"mvc\",\n",
    "    \"feature_engineering\":None,\n",
    "    \"k_fold_mode\":\"1 subject for testing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:44.258957Z",
     "iopub.status.busy": "2022-12-24T19:34:44.258087Z",
     "iopub.status.idle": "2022-12-24T19:34:44.268608Z",
     "shell.execute_reply": "2022-12-24T19:34:44.267567Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"model_name\": autoname(\"capg_dba_v003\"),\n",
    "    # General hyperparameters\n",
    "    \"in_features\": 128,\n",
    "    \"out_features\": 1,\n",
    "    # Sequence hyperparameters\n",
    "    \"in_seq_len_sec\": 0.1,\n",
    "    \"out_seq_len_sec\": 0,\n",
    "    \"data_sampling_rate_Hz\": 1000.0,\n",
    "    \"data_downsampling\": 5,\n",
    "    \"sequence_downsampling\": 1,\n",
    "    \"in_seq_len\": 0,\n",
    "    \"out_seq_len\": 0,\n",
    "    \"validation_data\": [0.05,'testset'],\n",
    "    # Convolution hyperparameters\n",
    "    \"num_conv_blocks\": 1,\n",
    "    \"conv_channels\": [64],\n",
    "    \"conv_kernel_size\": 3,\n",
    "    \"conv_padding\": \"valid\",\n",
    "    \"conv_activation\": \"relu\",\n",
    "    \"conv_activation_params\": None,\n",
    "    \"conv_batchnorm\": \"before\",\n",
    "    \"conv_batchnorm_params\": None,\n",
    "    \"conv_stride\": 1,\n",
    "    \"conv_dropout\": 0.3,\n",
    "    \"pool_padding\": 0,\n",
    "    \"pool_kernel_size\": 2,\n",
    "    \"pool_stride\": 1,\n",
    "    \"min_image_size\": 4,\n",
    "    # Dense hyperparameters\n",
    "    \"dense_width\": 64,\n",
    "    \"dense_depth\": 1,\n",
    "    \"dense_dropout\": 0.3,\n",
    "    \"dense_activation\": \"relu\",\n",
    "    \"dense_activation_params\": None,\n",
    "    \"output_activation\": None,\n",
    "    \"output_activation_params\": None,\n",
    "    \"dense_batchnorm\": \"before\",\n",
    "    \"dense_batchnorm_params\": None,\n",
    "    # Training hyperparameters\n",
    "    \"l2_reg\": None,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 40,\n",
    "    \"validation_tolerance_epochs\": 5000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"learning_rate_decay_gamma\": 0.95,\n",
    "    \"loss_function\": \"crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"optimizer_params\": None\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:44.272967Z",
     "iopub.status.busy": "2022-12-24T19:34:44.272238Z",
     "iopub.status.idle": "2022-12-24T19:34:48.075231Z",
     "shell.execute_reply": "2022-12-24T19:34:48.074070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file:  dba_subj_8.parquet\n",
      "Loading file:  dba_subj_10.parquet\n",
      "Loading file:  dba_subj_2.parquet\n",
      "Loading file:  dba_subj_5.parquet\n",
      "Loading file:  dba_subj_14.parquet\n",
      "Loading file:  dba_subj_12.parquet\n",
      "Loading file:  dba_subj_4.parquet\n",
      "Loading file:  dba_subj_11.parquet\n",
      "Loading file:  dba_subj_17.parquet\n",
      "Loading file:  dba_subj_16.parquet\n",
      "Loading file:  dba_subj_18.parquet\n",
      "Loading file:  dba_subj_6.parquet\n",
      "Loading file:  dba_subj_15.parquet\n",
      "Loading file:  dba_subj_3.parquet\n",
      "Loading file:  dba_subj_9.parquet\n",
      "Loading file:  dba_subj_13.parquet\n",
      "Loading file:  dba_subj_1.parquet\n",
      "Loading file:  dba_subj_7.parquet\n",
      "dba_tot shape:  (1476000, 131)\n",
      "dba_mvc shape:  (36000, 131)\n",
      "dba shape:  (1440000, 131)\n",
      "columns: \n",
      "Index(['subject', 'gesture', 'trial', 'b_1_c_1', 'b_1_c_2', 'b_1_c_3',\n",
      "       'b_1_c_4', 'b_1_c_5', 'b_1_c_6', 'b_1_c_7',\n",
      "       ...\n",
      "       'b_8_c_7', 'b_8_c_8', 'b_8_c_9', 'b_8_c_10', 'b_8_c_11', 'b_8_c_12',\n",
      "       'b_8_c_13', 'b_8_c_14', 'b_8_c_15', 'b_8_c_16'],\n",
      "      dtype='object', length=131)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/CAPG/parquet\"\n",
    "def load_single_capg_dataset(data_dir, db_str:str=\"dba\"):\n",
    "    data_lst = []\n",
    "    for i,file in enumerate(os.listdir(data_dir)):\n",
    "        if file.endswith(\".parquet\") and db_str in file:\n",
    "            print(\"Loading file: \", file)\n",
    "            data_lst.append(pd.read_parquet(os.path.join(data_dir, file)))\n",
    "    data = pd.concat(data_lst, axis=0, ignore_index=True)\n",
    "    return data\n",
    "dba_tot = load_single_capg_dataset(data_dir, db_str=\"dba\")\n",
    "dba_mvc = dba_tot.loc[dba_tot[\"gesture\"].isin([100, 101])]\n",
    "dba = dba_tot.loc[~dba_tot[\"gesture\"].isin([100, 101])]\n",
    "print(\"dba_tot shape: \", dba_tot.shape)\n",
    "print(\"dba_mvc shape: \", dba_mvc.shape)\n",
    "print(\"dba shape: \", dba.shape)\n",
    "print(\"columns: \")\n",
    "print(dba_tot.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize EMG Data\n",
    "\n",
    "Here the recorded MVC values will be used for normalizaing EMG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:48.079391Z",
     "iopub.status.busy": "2022-12-24T19:34:48.078715Z",
     "iopub.status.idle": "2022-12-24T19:34:53.928041Z",
     "shell.execute_reply": "2022-12-24T19:34:53.927382Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12313/1353078018.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dba.iloc[:,3:] = dba.iloc[:,3:].div(max_mvc, axis=1)\n"
     ]
    }
   ],
   "source": [
    "max_mvc = dba_mvc.iloc[:,3:].max(axis=0)\n",
    "del dba_mvc\n",
    "# print(\"max_mvc for 5 first channels: \")\n",
    "# print(max_mvc[:5])\n",
    "# print(\"shape of max_mvc: \", max_mvc.shape)\n",
    "# print(\"max of dba before normalization: (first five)\")\n",
    "# print(dba.iloc[:,3:].max(axis=0)[:5])\n",
    "dba.iloc[:,3:] = dba.iloc[:,3:].div(max_mvc, axis=1)\n",
    "# print(\"max of dba_norm after normalization: \")\n",
    "# print(dba_norm.iloc[:,3:].max(axis=0)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- k-fold study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform k-fold cross-validation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T19:34:53.933780Z",
     "iopub.status.busy": "2022-12-24T19:34:53.933139Z",
     "iopub.status.idle": "2022-12-24T20:53:44.318932Z",
     "shell.execute_reply": "2022-12-24T20:53:44.317857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################################################################\n",
      "Using subject 1 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [1]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [04:07<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 247.69 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 11.7906 | Accuracy: 0.2131\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 2 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [2]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [04:06<00:00,  6.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 246.46 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 2.3090 | Accuracy: 0.3678\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 3 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [3]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:47<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 227.02 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 2.7540 | Accuracy: 0.2521\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 4 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [4]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.94 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 3.9475 | Accuracy: 0.3186\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 5 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [5]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.69 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 1.9882 | Accuracy: 0.3661\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 6 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [6]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.64 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 3.9603 | Accuracy: 0.1480\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 7 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [7]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:47<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 227.43 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 11.6372 | Accuracy: 0.2096\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 8 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [8]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.31 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 4.2072 | Accuracy: 0.2938\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 9 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [9]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:47<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 227.14 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 32.4809 | Accuracy: 0.2880\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 10 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [10]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:52<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 232.66 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 6.3577 | Accuracy: 0.1537\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 11 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [11]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [04:18<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 258.93 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 27.6699 | Accuracy: 0.0714\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 12 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [12]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:47<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 227.13 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 5.2264 | Accuracy: 0.1653\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 13 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [13]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.10 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 2.7325 | Accuracy: 0.3318\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 14 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [14]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:44<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 224.57 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 9.9686 | Accuracy: 0.1365\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 15 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [15]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:46<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 226.23 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 2.2707 | Accuracy: 0.2028\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 16 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [16]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:49<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 229.23 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 4.1359 | Accuracy: 0.3578\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 17 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [17]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719811007\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:45<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 225.20 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 4.7878 | Accuracy: 0.2462\n",
      "Done.\n",
      "\n",
      "#################################################################\n",
      "Using subject 18 for testing ...\n",
      "#################################################################\n",
      "\n",
      "# subjects:    18\n",
      "# conditions:  8\n",
      "# trials:      10\n",
      "\n",
      "\n",
      "subjects used for testing:    [18]\n",
      "conditions used for testing:  []\n",
      "trials used for testing:      []\n",
      "\n",
      "\n",
      "Iterating through all trials ...\n",
      "\n",
      "Concatenating arrays and generating outputs ...\n",
      "Validation data source:   testset\n",
      "Validation data portion:  0.05\n",
      "x_train:  (272000, 32, 128)\n",
      "y_train:  (272000, 1)\n",
      "x_val:  (800, 32, 128)\n",
      "y_val:  (800, 1)\n",
      "x_test:  (15200, 32, 128)\n",
      "y_test:  (15200, 1)\n",
      "Constructing output dictionary ...\n",
      "Size of output dictionary in bytes:  4719810979\n",
      "Done.\n",
      "\n",
      "x_train shape:  (272000, 128, 32)\n",
      "x_val shape:  (800, 128, 32)\n",
      "x_test shape:  (15200, 128, 32)\n",
      "y_train shape:  (272000, 1)\n",
      "y_val shape:  (800, 1)\n",
      "y_test shape:  (15200, 1)\n",
      "Total number of data points:      272800\n",
      "Number of training data points:   272000\n",
      "Number of validation data points: 800\n",
      "Number of training batches:    1063\n",
      "Number of validation batches:  4\n",
      "Batch size:                    256\n",
      "Shape of training input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of training output from the dataloader:  torch.Size([256])\n",
      "Shape of validation input from the dataloader:   torch.Size([256, 128, 32])\n",
      "Shape of validation output from the dataloader:  torch.Size([256])\n",
      "Selected device:  cuda:0\n",
      "The learning rate has an exponential decay rate of 0.95000.\n",
      "Classification problem detected. We will look at accuracies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|████████████████████████████████████████████| 40/40 [03:44<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training.\n",
      "Training process took 224.13 seconds.\n",
      "Done training.\n",
      "Preparing data...\n",
      "selected device:  cuda\n",
      "Evaluating model...\n",
      "[███████████████████████████████████████] Loss: 1.9577 | Accuracy: 0.3469\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Define input columns\n",
    "input_cols = list(dba.iloc[:,3:].columns)\n",
    "\n",
    "# Hard-code total number of trials\n",
    "NUM_SUBJECTS = 18\n",
    "\n",
    "for k in range(NUM_SUBJECTS):\n",
    "    \n",
    "    print(\"\\n#################################################################\")\n",
    "    print(\"Using subject %d for testing ...\" % (k+1))\n",
    "    print(\"#################################################################\\n\")\n",
    "    \n",
    "    subj_for_testing = [k+1]\n",
    "    \n",
    "    # Un-Correct the output feature count (this is buggy behavior and should be fixed)\n",
    "    hparams['out_features'] = 1\n",
    "    \n",
    "    # Get processed data cell\n",
    "    data_processed = generate_cell_array(\n",
    "        dba, hparams,\n",
    "        subjects_column=\"subject\", conditions_column=\"gesture\", trials_column=\"trial\",\n",
    "        input_cols=input_cols, output_cols=[\"gesture\"], specific_conditions=None,\n",
    "        input_preprocessor=None,\n",
    "        output_preprocessor=None,\n",
    "        subjects_for_testing=subj_for_testing,\n",
    "        input_scaling=False, output_scaling=False, input_forward_facing=True, output_forward_facing=True, \n",
    "        data_squeezed=False,\n",
    "        input_towards_future=False, output_towards_future=False, \n",
    "        output_include_current_timestep=True,\n",
    "        use_filtered_data=False, #lpcutoff=CUTOFF, lporder=FILT_ORDER, lpsamplfreq=SAMPL_FREQ,\n",
    "        return_data_arrays_orig=False,\n",
    "        return_data_arrays_processed=False,\n",
    "        return_train_val_test_arrays=False,\n",
    "        return_train_val_test_data=True,\n",
    "        verbosity=1\n",
    "    )\n",
    "    \n",
    "    # Correct the output feature count (this is buggy behavior and should be fixed)\n",
    "    hparams['out_features'] = 8\n",
    "    \n",
    "    # Inputs MUST have shape (batch_size, num_channels, seq_length) for 1D CNN (opposite of RNN)\n",
    "    x_train = data_processed[\"x_train\"].transpose(0,2,1)\n",
    "    x_val = data_processed[\"x_val\"].transpose(0,2,1)\n",
    "    x_test = data_processed[\"x_test\"].transpose(0,2,1)\n",
    "    # Outputs MUST be zero-indexed class labels\n",
    "    y_train = data_processed[\"y_train\"] - 1\n",
    "    y_val = data_processed[\"y_val\"] - 1\n",
    "    y_test = data_processed[\"y_test\"] - 1\n",
    "    print(\"x_train shape: \", x_train.shape)\n",
    "    print(\"x_val shape: \", x_val.shape)\n",
    "    print(\"x_test shape: \", x_test.shape)\n",
    "    print(\"y_train shape: \", y_train.shape)\n",
    "    print(\"y_val shape: \", y_val.shape)\n",
    "    print(\"y_test shape: \", y_test.shape)\n",
    "    # Targets need to be squeezed for the loss function. It wants (N,) or (N,C) where C > 1, not (N,1).\n",
    "    y_train = y_train.squeeze()\n",
    "    y_val = y_val.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "    # Make datasets from training, validation and test sets\n",
    "    train_set = TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).long())\n",
    "    val_set = TensorDataset(torch.from_numpy(x_val).float(), torch.from_numpy(y_val).long())\n",
    "    test_set = TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).long())\n",
    "    \n",
    "    # If it is the first iteration of the loop, save the hyperparameters dictionary in the k-fold study dictionary\n",
    "    if k==0:\n",
    "        k_fold_study['hparams'] = hparams\n",
    "    \n",
    "    # Construct model\n",
    "    model = Image2Dense1D(hparams)\n",
    "    # print(model)\n",
    "    \n",
    "    # Train model\n",
    "    history = model.train_model([train_set, val_set], verbose=1, script_before_save=False, saveto=None)\n",
    "    \n",
    "    # Update relevant fields in the k-fold study dictionary\n",
    "    k_fold_study['history_training_loss'].append(history[\"training_loss\"])\n",
    "    k_fold_study[\"history_validation_loss\"].append(history[\"validation_loss\"])\n",
    "    k_fold_study[\"history_training_metrics\"].append(history[\"training_metrics\"])\n",
    "    k_fold_study[\"history_validation_metrics\"].append(history[\"validation_metrics\"])\n",
    "    k_fold_study[\"training_accuracies\"].append(history[\"training_metrics\"][-1])\n",
    "    k_fold_study[\"validation_accuracies\"].append(history[\"validation_metrics\"][-1])\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    results = model.evaluate_model(test_set, verbose=True, num_workers=0)\n",
    "    k_fold_study[\"testset_accuracies\"].append(results[\"metrics\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving k-fold study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T20:53:44.324721Z",
     "iopub.status.busy": "2022-12-24T20:53:44.324372Z",
     "iopub.status.idle": "2022-12-24T20:53:44.346132Z",
     "shell.execute_reply": "2022-12-24T20:53:44.345045Z"
    }
   },
   "outputs": [],
   "source": [
    "json.dump(k_fold_study, open(make_path(\"../results/\"+hparams['model_name']+\"/k_fold_study.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving general statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T20:53:44.351480Z",
     "iopub.status.busy": "2022-12-24T20:53:44.350952Z",
     "iopub.status.idle": "2022-12-24T20:53:44.412126Z",
     "shell.execute_reply": "2022-12-24T20:53:44.411226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of general results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testset_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.824071</td>\n",
       "      <td>0.242153</td>\n",
       "      <td>0.248308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.085459</td>\n",
       "      <td>0.090743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.818022</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.071382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.820419</td>\n",
       "      <td>0.171250</td>\n",
       "      <td>0.174638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.823176</td>\n",
       "      <td>0.245625</td>\n",
       "      <td>0.249145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.826153</td>\n",
       "      <td>0.315312</td>\n",
       "      <td>0.328520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.834743</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>0.367829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       training_accuracy  validation_accuracy  testset_accuracy\n",
       "count          18.000000            18.000000         18.000000\n",
       "mean            0.824071             0.242153          0.248308\n",
       "std             0.004926             0.085459          0.090743\n",
       "min             0.818022             0.062500          0.071382\n",
       "25%             0.820419             0.171250          0.174638\n",
       "50%             0.823176             0.245625          0.249145\n",
       "75%             0.826153             0.315312          0.328520\n",
       "max             0.834743             0.367500          0.367829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn_acc_arr = np.array(k_fold_study[\"training_accuracies\"])\n",
    "val_acc_arr = np.array(k_fold_study[\"validation_accuracies\"])\n",
    "tst_acc_arr = np.array(k_fold_study[\"testset_accuracies\"])\n",
    "general_dict = {\"training_accuracy\":trn_acc_arr, \"validation_accuracy\":val_acc_arr, \"testset_accuracy\":tst_acc_arr}\n",
    "general_results = pd.DataFrame(general_dict)\n",
    "print(\"Description of general results:\")\n",
    "general_results_describe = general_results.describe()\n",
    "display(general_results_describe)\n",
    "general_results_describe.to_csv(\n",
    "    make_path(\"../results/\"+hparams['model_name']+\"/general_results.csv\"), header=True, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting training histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T20:53:44.417171Z",
     "iopub.status.busy": "2022-12-24T20:53:44.416884Z",
     "iopub.status.idle": "2022-12-24T20:53:45.419094Z",
     "shell.execute_reply": "2022-12-24T20:53:45.418204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_loss:  (18, 40)\n",
      "Shape of train_loss_mean:  (40,)\n",
      "Shape of train_loss_std:  (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = np.array(k_fold_study[\"history_training_loss\"])\n",
    "val_loss = np.array(k_fold_study[\"history_validation_loss\"])\n",
    "train_acc = np.array(k_fold_study[\"history_training_metrics\"])\n",
    "val_acc = np.array(k_fold_study[\"history_validation_metrics\"])\n",
    "\n",
    "print(\"Shape of train_loss: \", train_loss.shape)\n",
    "\n",
    "train_loss_mean = np.mean(train_loss, axis=0)\n",
    "train_loss_std = np.std(train_loss, axis=0)# / 2\n",
    "val_loss_mean = np.mean(val_loss, axis=0)\n",
    "val_loss_std = np.std(val_loss, axis=0)# / 2\n",
    "train_acc_mean = np.mean(train_acc, axis=0)\n",
    "train_acc_std = np.std(train_acc, axis=0)# / 2\n",
    "val_acc_mean = np.mean(val_acc, axis=0)\n",
    "val_acc_std = np.std(val_acc, axis=0)# / 2\n",
    "\n",
    "print(\"Shape of train_loss_mean: \", train_loss_mean.shape)\n",
    "print(\"Shape of train_loss_std: \", train_loss_std.shape)\n",
    "\n",
    "epochs = hparams['epochs']\n",
    "epochs = np.arange(1, epochs+1)\n",
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.subplot(2,1,1)\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, train_loss_mean, label=\"Training\", color=\"blue\")\n",
    "plt.fill_between(epochs, train_loss_mean-train_loss_std, train_loss_mean+train_loss_std, \n",
    "                 color='blue', alpha=0.2)\n",
    "plt.plot(epochs, val_loss_mean, label=\"Validation\", color=\"orange\")\n",
    "plt.fill_between(epochs, val_loss_mean-val_loss_std, val_loss_mean+val_loss_std,\n",
    "                 color='orange', alpha=0.2)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, train_acc_mean, color=\"blue\")\n",
    "plt.fill_between(epochs, train_acc_mean-train_acc_std, train_acc_mean+train_acc_std,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.plot(epochs, val_acc_mean, color=\"orange\")\n",
    "plt.fill_between(epochs, val_acc_mean-val_acc_std, val_acc_mean+val_acc_std,\n",
    "                 color='orange', alpha=0.2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(make_path(\"../results/\"+hparams['model_name']+\"/training_history.png\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9063ff2262220159f9d0422687c0477cf7937962d72300ed35684f58e95be43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
