{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition with CAPG DBA dataset\n",
    "\n",
    "In this preliminary effort, we will try to perform hand gesture recognition from CAPG DBA dataset.\n",
    "\n",
    "In this version:\n",
    "\n",
    "- EMG data is normalized with the recorded MVC data\n",
    "- EMG data (already preprocessed) **will not be processed** further.\n",
    "- There is **no feature engineering**; raw EMG data will be used.\n",
    "- **2D CNN** architecture used in the Capg paper will be used.\n",
    "- **Input** to the model is 8 x 6 image containing 8 bands of 16 HD-EMG channels, with no temporal information at all.\n",
    "- **Training data:** 5 trials per subject per gesture\n",
    "- **Test data:** 5 trials per subject per gesture\n",
    "\n",
    "**NOTE** This code has been tested with:\n",
    "```\n",
    "    numpy version:        1.23.5\n",
    "    scipy version:        1.9.3\n",
    "    sklearn version:      1.2.0\n",
    "    seaborn version:      0.12.1\n",
    "    pandas version:       1.5.2\n",
    "    torch version:        1.12.1+cu113\n",
    "    matplotlib version:   3.6.2\n",
    "    CUDA version:         11.2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Preliminaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "direc = os.getcwd()\n",
    "print(\"Current Working Directory is: \", direc)\n",
    "KUACC = False\n",
    "if \"scratch\" in direc: # We are using the cluster\n",
    "    KUACC = True\n",
    "    homedir = os.path.expanduser(\"~\")\n",
    "    os.chdir(os.path.join(homedir,\"REPO/comp541-project/capg_replica\"))\n",
    "    direc = os.getcwd()\n",
    "    print(\"Current Working Directory is now: \", direc)\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../data/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets_torch import *\n",
    "from models_torch import *\n",
    "from utils_torch import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import statistics\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# Print versions\n",
    "print(\"numpy version:       \", np.__version__)\n",
    "print(\"scipy version:       \", sp.__version__)\n",
    "print(\"sklearn version:     \", sklearn.__version__)\n",
    "print(\"seaborn version:     \", sns.__version__)\n",
    "print(\"pandas version:      \", pd.__version__)\n",
    "print(\"torch version:       \", torch.__version__)\n",
    "print(\"matplotlib version:  \", matplotlib.__version__)\n",
    "\n",
    "\n",
    "# Checking to see if CUDA is available for us\n",
    "print(\"Checking to see if PyTorch recognizes GPU...\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Whether to use latex rendering in plots throughout the notebook\n",
    "USE_TEX = False\n",
    "FONT_SIZE = 12\n",
    "\n",
    "# Setting matplotlib plotting variables\n",
    "if USE_TEX:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Computer Modern Roman\"]\n",
    "    })\n",
    "else:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\"]\n",
    "    })\n",
    "\n",
    "# Do not plot figures inline (only useful for cluster)\n",
    "# %matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Hyperparameters and Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = {\n",
    "    'code':'capg_replica/capg_dba_v001',\n",
    "    'package':'torch',\n",
    "    'dataset':'capg',\n",
    "    'subdataset':'dba'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"model_name\": autoname(\"capg_replica_dba_v001\"),\n",
    "    # General hyperparameters\n",
    "    \"in_features\": 128,\n",
    "    \"out_features\": 1,\n",
    "    # Sequence hyperparameters\n",
    "    \"in_seq_len_sec\": 0,\n",
    "    \"out_seq_len_sec\": 0,\n",
    "    \"data_sampling_rate_Hz\": 1000.0,\n",
    "    \"data_downsampling\": 1,\n",
    "    \"sequence_downsampling\": 1,\n",
    "    \"in_seq_len\": 0,\n",
    "    \"out_seq_len\": 0,\n",
    "    \"validation_data\": [0.05,'testset']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/CAPG/parquet\"\n",
    "def load_single_capg_dataset(data_dir, db_str:str=\"dba\"):\n",
    "    data_lst = []\n",
    "    for i,file in enumerate(os.listdir(data_dir)):\n",
    "        if file.endswith(\".parquet\") and db_str in file:\n",
    "            print(\"Loading file: \", file)\n",
    "            data_lst.append(pd.read_parquet(os.path.join(data_dir, file)))\n",
    "    data = pd.concat(data_lst, axis=0, ignore_index=True)\n",
    "    return data\n",
    "dba_tot = load_single_capg_dataset(data_dir, db_str=\"dba\")\n",
    "dba_mvc = dba_tot.loc[dba_tot[\"gesture\"].isin([100, 101])]\n",
    "dba = dba_tot.loc[~dba_tot[\"gesture\"].isin([100, 101])]\n",
    "print(\"dba_tot shape: \", dba_tot.shape)\n",
    "print(\"dba_mvc shape: \", dba_mvc.shape)\n",
    "print(\"dba shape: \", dba.shape)\n",
    "print(\"columns: \")\n",
    "print(dba_tot.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize EMG Data\n",
    "\n",
    "Here the recorded MVC values will be used for normalizaing EMG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mvc = dba_mvc.iloc[:,3:].max(axis=0)\n",
    "del dba_mvc\n",
    "# print(\"max_mvc for 5 first channels: \")\n",
    "# print(max_mvc[:5])\n",
    "# print(\"shape of max_mvc: \", max_mvc.shape)\n",
    "# print(\"max of dba before normalization: (first five)\")\n",
    "# print(dba.iloc[:,3:].max(axis=0)[:5])\n",
    "dba.iloc[:,3:] = dba.iloc[:,3:].div(max_mvc, axis=1)\n",
    "# print(\"max of dba_norm after normalization: \")\n",
    "# print(dba_norm.iloc[:,3:].max(axis=0)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tabulated data (and update hyperparameters accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = list(dba.iloc[:,3:].columns)\n",
    "data_processed = generate_cell_array(\n",
    "    dba, hparams,\n",
    "    subjects_column=\"subject\", conditions_column=\"gesture\", trials_column=\"trial\",\n",
    "    input_cols=input_cols, output_cols=[\"gesture\"], specific_conditions=None,\n",
    "    input_preprocessor=None,\n",
    "    output_preprocessor=None,\n",
    "    input_postprocessor=lambda arr: arr.reshape(-1,1,8,16),\n",
    "    subjects_for_testing=None, \n",
    "    trials_for_testing=[6,7,8,9,10],\n",
    "    input_scaling=False, output_scaling=False, input_forward_facing=True, output_forward_facing=True, \n",
    "    data_squeezed=False,\n",
    "    input_towards_future=False, output_towards_future=False, \n",
    "    output_include_current_timestep=True,\n",
    "    use_filtered_data=False, #lpcutoff=CUTOFF, lporder=FILT_ORDER, lpsamplfreq=SAMPL_FREQ,\n",
    "    return_data_arrays_orig=False,\n",
    "    return_data_arrays_processed=False,\n",
    "    return_train_val_test_arrays=False,\n",
    "    return_train_val_test_data=True,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# Get rid of things we won't need anymore\n",
    "del dba, dba_tot\n",
    "\n",
    "# Correct output feature count (this is buggy behavior and should be fixed)\n",
    "hparams['out_features'] = 8\n",
    "study['hparams'] = hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs MUST have shape (batch_size, num_channels, seq_length) for 1D CNN (opposite of RNN)\n",
    "x_train = data_processed[\"x_train\"]#.transpose(0,2,1)\n",
    "x_val = data_processed[\"x_val\"]#.transpose(0,2,1)\n",
    "x_test = data_processed[\"x_test\"]#.transpose(0,2,1)\n",
    "# Outputs MUST be zero-indexed class labels\n",
    "y_train = data_processed[\"y_train\"] - 1\n",
    "y_val = data_processed[\"y_val\"] - 1\n",
    "y_test = data_processed[\"y_test\"] - 1\n",
    "del data_processed\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_val shape: \", x_val.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_val shape: \", y_val.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.squeeze()\n",
    "y_val = y_val.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).long())\n",
    "val_set = TensorDataset(torch.from_numpy(x_val).float(), torch.from_numpy(y_val).long())\n",
    "test_set = TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).long())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapgMyoModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapgMyoModel, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.BatchNorm2d(1))\n",
    "        layers.append(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=[3,3], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3,3], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[1,1], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[1,1], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout2d(0.5))\n",
    "        \n",
    "        layers.append(nn.Flatten())\n",
    "        \n",
    "        layers.append(nn.Linear(64*8*16, 512))\n",
    "        layers.append(nn.BatchNorm1d(512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        layers.append(nn.Linear(512, 512))\n",
    "        layers.append(nn.BatchNorm1d(512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        layers.append(nn.Linear(512, 128))\n",
    "        layers.append(nn.BatchNorm1d(128))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(128, 8))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "model = CapgMyoModel()\n",
    "print(model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_pytorch_model(\n",
    "    model, [train_set, val_set], batch_size=1024, loss_str='crossentropy', optimizer_str='adam', \n",
    "    optimizer_params={'weight_decay':0.0001}, loss_function_params=None, learnrate=0.1, \n",
    "    learnrate_decay_gamma=0.95, epochs=200, validation_patience=10, \n",
    "    verbose=1, script_before_save=True, saveto=None, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study['training_history'] = history\n",
    "json.dump(study, open(make_path(\"../results/\"+hparams[\"model_name\"]+\"/study.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(8,8), dpi=100)\n",
    "plt.subplot(2,1,1)\n",
    "plt.grid(True)\n",
    "plt.plot(history[\"training_loss\"], label=\"train\")\n",
    "plt.plot(history[\"validation_loss\"], label=\"val\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.grid(True)\n",
    "plt.plot(history[\"training_metrics\"], label=\"train\")\n",
    "plt.plot(history[\"validation_metrics\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.subplots_adjust(\n",
    "    hspace=0.2\n",
    ")\n",
    "\n",
    "plt.savefig(make_path(\"../results/\"+hparams['model_name']+\"/training_history.png\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9063ff2262220159f9d0422687c0477cf7937962d72300ed35684f58e95be43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
