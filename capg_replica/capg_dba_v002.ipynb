{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition with CAPG DB-a Dataset (one trial for testing)\n",
    "\n",
    "In this preliminary effort, we will try to perform hand gesture recognition from CAPG DBA dataset.\n",
    "\n",
    "In this version:\n",
    "\n",
    "- EMG data is normalized with the recorded MVC data\n",
    "- EMG data (already preprocessed) **will not be processed** further.\n",
    "- There is **no feature engineering**; raw EMG data will be used.\n",
    "- The **2D ConvNet** architecture used in the CapgMyo paper will be exactly replicated.\n",
    "- **Training data:** 9 trials per subject per gesture\n",
    "- **Test data:** 1 trial per subject per gesture\n",
    "- K-fold cross-validation will be performed.\n",
    "\n",
    "**NOTE** This code has been tested with:\n",
    "```\n",
    "    numpy version:        1.23.5\n",
    "    scipy version:        1.9.3\n",
    "    sklearn version:      1.2.0\n",
    "    seaborn version:      0.12.1\n",
    "    pandas version:       1.5.2\n",
    "    torch version:        1.12.1+cu113\n",
    "    matplotlib version:   3.6.2\n",
    "    CUDA version:         11.2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Preliminaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "direc = os.getcwd()\n",
    "print(\"Current Working Directory is: \", direc)\n",
    "KUACC = False\n",
    "if \"scratch\" in direc: # We are using the cluster\n",
    "    KUACC = True\n",
    "    homedir = os.path.expanduser(\"~\")\n",
    "    os.chdir(os.path.join(homedir,\"REPO/comp541-project/capg_replica/\"))\n",
    "    direc = os.getcwd()\n",
    "    print(\"Current Working Directory is now: \", direc)\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../data/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets_torch import *\n",
    "from models_torch import *\n",
    "from utils_torch import *\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import statistics\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "# Print versions\n",
    "print(\"numpy version:       \", np.__version__)\n",
    "print(\"scipy version:       \", sp.__version__)\n",
    "print(\"sklearn version:     \", sklearn.__version__)\n",
    "print(\"seaborn version:     \", sns.__version__)\n",
    "print(\"pandas version:      \", pd.__version__)\n",
    "print(\"torch version:       \", torch.__version__)\n",
    "print(\"matplotlib version:  \", matplotlib.__version__)\n",
    "\n",
    "\n",
    "# Checking to see if CUDA is available for us\n",
    "print(\"Checking to see if PyTorch recognizes GPU...\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Whether to use latex rendering in plots throughout the notebook\n",
    "USE_TEX = False\n",
    "FONT_SIZE = 12\n",
    "\n",
    "# Setting matplotlib plotting variables\n",
    "if USE_TEX:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Computer Modern Roman\"]\n",
    "    })\n",
    "else:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"font.size\": FONT_SIZE,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\"]\n",
    "    })\n",
    "\n",
    "# Do not plot figures inline (only useful for cluster)\n",
    "# %matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Hyperparameters and Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings of the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_study = {\n",
    "    'code':'capg_replica/capg_dba_v002',\n",
    "    'package':'torch',\n",
    "    'dataset':'capg',\n",
    "    'subdataset':'dba',\n",
    "    \"training_accuracies\": [],\n",
    "    \"validation_accuracies\": [],\n",
    "    \"testset_accuracies\": [],\n",
    "    \"history_training_loss\": [],\n",
    "    \"history_training_metrics\": [],\n",
    "    \"history_validation_loss\": [],\n",
    "    \"history_validation_metrics\": [],\n",
    "    \"preprocessing\":\"mvc\",\n",
    "    \"feature_engineering\":None,\n",
    "    \"k_fold_mode\":\"1 trial for testing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"model_name\": autoname(\"capg_replica_dba_v002\"),\n",
    "    # General hyperparameters\n",
    "    \"in_features\": 128,\n",
    "    \"out_features\": 1,\n",
    "    # Sequence hyperparameters\n",
    "    \"in_seq_len_sec\": 0,\n",
    "    \"out_seq_len_sec\": 0,\n",
    "    \"data_sampling_rate_Hz\": 1000.0,\n",
    "    \"data_downsampling\": 5,\n",
    "    \"sequence_downsampling\": 1,\n",
    "    \"in_seq_len\": 0,\n",
    "    \"out_seq_len\": 0,\n",
    "    \"validation_data\": [0.05,'testset']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/CAPG/parquet\"\n",
    "def load_single_capg_dataset(data_dir, db_str:str=\"dba\"):\n",
    "    data_lst = []\n",
    "    for i,file in enumerate(os.listdir(data_dir)):\n",
    "        if file.endswith(\".parquet\") and db_str in file:\n",
    "            print(\"Loading file: \", file)\n",
    "            data_lst.append(pd.read_parquet(os.path.join(data_dir, file)))\n",
    "    data = pd.concat(data_lst, axis=0, ignore_index=True)\n",
    "    return data\n",
    "dba_tot = load_single_capg_dataset(data_dir, db_str=\"dba\")\n",
    "dba_mvc = dba_tot.loc[dba_tot[\"gesture\"].isin([100, 101])]\n",
    "dba = dba_tot.loc[~dba_tot[\"gesture\"].isin([100, 101])]\n",
    "print(\"dba_tot shape: \", dba_tot.shape)\n",
    "print(\"dba_mvc shape: \", dba_mvc.shape)\n",
    "print(\"dba shape: \", dba.shape)\n",
    "print(\"columns: \")\n",
    "print(dba_tot.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize EMG Data\n",
    "\n",
    "Here the recorded MVC values will be used for normalizaing EMG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mvc = dba_mvc.iloc[:,3:].max(axis=0)\n",
    "del dba_mvc\n",
    "# print(\"max_mvc for 5 first channels: \")\n",
    "# print(max_mvc[:5])\n",
    "# print(\"shape of max_mvc: \", max_mvc.shape)\n",
    "# print(\"max of dba before normalization: (first five)\")\n",
    "# print(dba.iloc[:,3:].max(axis=0)[:5])\n",
    "dba.iloc[:,3:] = dba.iloc[:,3:].div(max_mvc, axis=1)\n",
    "# print(\"max of dba_norm after normalization: \")\n",
    "# print(dba_norm.iloc[:,3:].max(axis=0)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- k-fold study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CapgMyo paper's ConvNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapgMyoModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapgMyoModel, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.BatchNorm2d(1))\n",
    "        layers.append(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=[3,3], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3,3], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[1,1], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[1,1], padding='same'))\n",
    "        layers.append(nn.BatchNorm2d(64))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout2d(0.5))\n",
    "        \n",
    "        layers.append(nn.Flatten())\n",
    "        \n",
    "        layers.append(nn.Linear(64*8*16, 512))\n",
    "        layers.append(nn.BatchNorm1d(512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        layers.append(nn.Linear(512, 512))\n",
    "        layers.append(nn.BatchNorm1d(512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(0.5))\n",
    "        \n",
    "        layers.append(nn.Linear(512, 128))\n",
    "        layers.append(nn.BatchNorm1d(128))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(128, 8))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "model = CapgMyoModel()\n",
    "print(model)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform k-fold cross-validation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input columns\n",
    "input_cols = list(dba.iloc[:,3:].columns)\n",
    "\n",
    "# Hard-code total number of trials\n",
    "NUM_TRIALS = 10\n",
    "\n",
    "for k in range(NUM_TRIALS):\n",
    "    \n",
    "    print(\"\\n#################################################################\")\n",
    "    print(\"Using trial %d for testing ...\" % (k+1))\n",
    "    print(\"#################################################################\\n\")\n",
    "    \n",
    "    trial_for_testing = [k+1]\n",
    "    \n",
    "    # Un-Correct the output feature count (this is buggy behavior and should be fixed)\n",
    "    hparams['out_features'] = 1\n",
    "    \n",
    "    # Get processed data cell\n",
    "    data_processed = generate_cell_array(\n",
    "        dba, hparams,\n",
    "        subjects_column=\"subject\", conditions_column=\"gesture\", trials_column=\"trial\",\n",
    "        input_cols=input_cols, output_cols=[\"gesture\"], specific_conditions=None,\n",
    "        input_preprocessor=None,\n",
    "        output_preprocessor=None,\n",
    "        input_postprocessor=lambda arr: arr.reshape(-1,1,8,16),\n",
    "        subjects_for_testing=None, \n",
    "        trials_for_testing=trial_for_testing,\n",
    "        input_scaling=False, output_scaling=False, input_forward_facing=True, output_forward_facing=True, \n",
    "        data_squeezed=False,\n",
    "        input_towards_future=False, output_towards_future=False, \n",
    "        output_include_current_timestep=True,\n",
    "        use_filtered_data=False, #lpcutoff=CUTOFF, lporder=FILT_ORDER, lpsamplfreq=SAMPL_FREQ,\n",
    "        return_data_arrays_orig=False,\n",
    "        return_data_arrays_processed=False,\n",
    "        return_train_val_test_arrays=False,\n",
    "        return_train_val_test_data=True,\n",
    "        verbosity=1\n",
    "    )\n",
    "    \n",
    "    # Correct the output feature count (this is buggy behavior and should be fixed)\n",
    "    hparams['out_features'] = 8\n",
    "    \n",
    "    # Inputs MUST have correct shape\n",
    "    x_train = data_processed[\"x_train\"]\n",
    "    x_val = data_processed[\"x_val\"]\n",
    "    x_test = data_processed[\"x_test\"]\n",
    "    # Outputs MUST be zero-indexed class labels\n",
    "    y_train = data_processed[\"y_train\"] - 1\n",
    "    y_val = data_processed[\"y_val\"] - 1\n",
    "    y_test = data_processed[\"y_test\"] - 1\n",
    "    print(\"x_train shape: \", x_train.shape)\n",
    "    print(\"x_val shape: \", x_val.shape)\n",
    "    print(\"x_test shape: \", x_test.shape)\n",
    "    print(\"y_train shape: \", y_train.shape)\n",
    "    print(\"y_val shape: \", y_val.shape)\n",
    "    print(\"y_test shape: \", y_test.shape)\n",
    "    # Targets need to be squeezed for the loss function. It wants (N,) or (N,C) where C > 1, not (N,1).\n",
    "    y_train = y_train.squeeze()\n",
    "    y_val = y_val.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "    # Make datasets from training, validation and test sets\n",
    "    train_set = TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(y_train).long())\n",
    "    val_set = TensorDataset(torch.from_numpy(x_val).float(), torch.from_numpy(y_val).long())\n",
    "    test_set = TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(y_test).long())\n",
    "    \n",
    "    # If it is the first iteration of the loop, save the hyperparameters dictionary in the k-fold study dictionary\n",
    "    if k==0:\n",
    "        k_fold_study['hparams'] = hparams\n",
    "    \n",
    "    # Construct model\n",
    "    model = CapgMyoModel()\n",
    "    # print(model)\n",
    "    \n",
    "    # Train model\n",
    "    history = train_pytorch_model(\n",
    "        model, [train_set, val_set], batch_size=1024, loss_str='crossentropy', optimizer_str='adam', \n",
    "        optimizer_params={'weight_decay':0.0001}, loss_function_params=None, learnrate=0.1, \n",
    "        learnrate_decay_gamma=0.95, epochs=200, validation_patience=1000000, \n",
    "        verbose=1, script_before_save=True, saveto=None, num_workers=0)    \n",
    "    \n",
    "    # Update relevant fields in the k-fold study dictionary\n",
    "    k_fold_study['history_training_loss'].append(history[\"training_loss\"])\n",
    "    k_fold_study[\"history_validation_loss\"].append(history[\"validation_loss\"])\n",
    "    k_fold_study[\"history_training_metrics\"].append(history[\"training_metrics\"])\n",
    "    k_fold_study[\"history_validation_metrics\"].append(history[\"validation_metrics\"])\n",
    "    k_fold_study[\"training_accuracies\"].append(history[\"training_metrics\"][-1])\n",
    "    k_fold_study[\"validation_accuracies\"].append(history[\"validation_metrics\"][-1])\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    results = evaluate_pytorch_model(model, test_set, loss_str='crossentropy', loss_function_params=None,\n",
    "    batch_size=1024, device_str=\"cuda\", verbose=True, num_workers=0)\n",
    "    \n",
    "    k_fold_study[\"testset_accuracies\"].append(results[\"metrics\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving k-fold study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(k_fold_study, open(make_path(\"../results/\"+hparams['model_name']+\"/k_fold_study.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving general statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_acc_arr = np.array(k_fold_study[\"training_accuracies\"])\n",
    "val_acc_arr = np.array(k_fold_study[\"validation_accuracies\"])\n",
    "tst_acc_arr = np.array(k_fold_study[\"testset_accuracies\"])\n",
    "general_dict = {\"training_accuracy\":trn_acc_arr, \"validation_accuracy\":val_acc_arr, \"testset_accuracy\":tst_acc_arr}\n",
    "general_results = pd.DataFrame(general_dict)\n",
    "print(\"Description of general results:\")\n",
    "general_results_describe = general_results.describe()\n",
    "display(general_results_describe)\n",
    "general_results_describe.to_csv(\n",
    "    make_path(\"../results/\"+hparams['model_name']+\"/general_results.csv\"), header=True, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting training histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import json\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_fold_study = json.load(open(\"../results/capg_replica_dba_v002_2023_01_07_20_07_25/k_fold_study.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.array(k_fold_study[\"history_training_loss\"])\n",
    "val_loss = np.array(k_fold_study[\"history_validation_loss\"])\n",
    "train_acc = np.array(k_fold_study[\"history_training_metrics\"])\n",
    "val_acc = np.array(k_fold_study[\"history_validation_metrics\"])\n",
    "\n",
    "print(\"Shape of train_loss: \", train_loss.shape)\n",
    "\n",
    "train_loss_mean = np.mean(train_loss, axis=0)\n",
    "train_loss_std = np.std(train_loss, axis=0)# / 2\n",
    "val_loss_mean = np.mean(val_loss, axis=0)\n",
    "val_loss_std = np.std(val_loss, axis=0)# / 2\n",
    "train_acc_mean = np.mean(train_acc, axis=0)\n",
    "train_acc_std = np.std(train_acc, axis=0)# / 2\n",
    "val_acc_mean = np.mean(val_acc, axis=0)\n",
    "val_acc_std = np.std(val_acc, axis=0)# / 2\n",
    "\n",
    "print(\"Shape of train_loss_mean: \", train_loss_mean.shape)\n",
    "print(\"Shape of train_loss_std: \", train_loss_std.shape)\n",
    "\n",
    "epochs = 200\n",
    "epochs = np.arange(1, epochs+1)\n",
    "plt.figure(figsize=(8,8), dpi=100)\n",
    "plt.subplot(2,1,1)\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, train_loss_mean, label=\"Training\", color=\"blue\")\n",
    "plt.fill_between(epochs, train_loss_mean-train_loss_std, train_loss_mean+train_loss_std, \n",
    "                 color='blue', alpha=0.2)\n",
    "plt.plot(epochs, val_loss_mean, label=\"Validation\", color=\"orange\")\n",
    "plt.fill_between(epochs, val_loss_mean-val_loss_std, val_loss_mean+val_loss_std,\n",
    "                 color='orange', alpha=0.2)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, train_acc_mean, color=\"blue\")\n",
    "plt.fill_between(epochs, train_acc_mean-train_acc_std, train_acc_mean+train_acc_std,\n",
    "                 color='blue', alpha=0.2)\n",
    "plt.plot(epochs, val_acc_mean, color=\"orange\")\n",
    "plt.fill_between(epochs, val_acc_mean-val_acc_std, val_acc_mean+val_acc_std,\n",
    "                 color='orange', alpha=0.2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.savefig(make_path(\"../results/\"+k_fold_study['hparams']['model_name']+\"/training_history.png\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9063ff2262220159f9d0422687c0477cf7937962d72300ed35684f58e95be43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
